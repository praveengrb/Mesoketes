{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNKC323kZPHyObKsQto+0rO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/praveengrb/Mesoketes/blob/master/NLTK_PreProcessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhRTgBgRIoS3",
        "outputId": "bcd8bd7a-b67b-402b-a4bd-c45896246a61"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "qKflGfgo4s_4"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentence and Word Tokenization"
      ],
      "metadata": {
        "id": "Uoceqzn6ISZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SAMPLE_TEXT='''Stop words are the words in a stop list (or stoplist or negative dictionary) which are filtered out (i.e. stopped) before or after processing of natural language data (text) because they are insignificant.[1] There is no single universal list of stop words used by all natural language processing tools, nor any agreed upon rules for identifying stop words, and indeed not all tools even use such a list. Therefore, any group of words can be chosen as the stop words for a given purpose. The \"general trend in [information retrieval] systems over time has been from standard use of quite large stop lists (200–300 terms) to very small stop lists (7–12 terms) to no stop list whatsoever\".[2]'''\n",
        "sent_tokenized_words=sent_tokenize(SAMPLE_TEXT)\n",
        "tokenized_words=word_tokenize(SAMPLE_TEXT)"
      ],
      "metadata": {
        "id": "OdBPtNyzIV8x"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sent_tokenized_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LjROwnBI8t3",
        "outputId": "b6ef54bf-bae0-430d-b6d7-5c9ffe8b9ec6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Stop words are the words in a stop list (or stoplist or negative dictionary) which are filtered out (i.e.', 'stopped) before or after processing of natural language data (text) because they are insignificant.', '[1] There is no single universal list of stop words used by all natural language processing tools, nor any agreed upon rules for identifying stop words, and indeed not all tools even use such a list.', 'Therefore, any group of words can be chosen as the stop words for a given purpose.', 'The \"general trend in [information retrieval] systems over time has been from standard use of quite large stop lists (200–300 terms) to very small stop lists (7–12 terms) to no stop list whatsoever\".', '[2]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HS4U3ISPJIHC",
        "outputId": "4a3f2c61-3ff9-46f0-8d4f-d70ca01af3f5"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Stop', 'words', 'are', 'the', 'words', 'in', 'a', 'stop', 'list', '(', 'or', 'stoplist', 'or', 'negative', 'dictionary', ')', 'which', 'are', 'filtered', 'out', '(', 'i.e', '.', 'stopped', ')', 'before', 'or', 'after', 'processing', 'of', 'natural', 'language', 'data', '(', 'text', ')', 'because', 'they', 'are', 'insignificant', '.', '[', '1', ']', 'There', 'is', 'no', 'single', 'universal', 'list', 'of', 'stop', 'words', 'used', 'by', 'all', 'natural', 'language', 'processing', 'tools', ',', 'nor', 'any', 'agreed', 'upon', 'rules', 'for', 'identifying', 'stop', 'words', ',', 'and', 'indeed', 'not', 'all', 'tools', 'even', 'use', 'such', 'a', 'list', '.', 'Therefore', ',', 'any', 'group', 'of', 'words', 'can', 'be', 'chosen', 'as', 'the', 'stop', 'words', 'for', 'a', 'given', 'purpose', '.', 'The', '``', 'general', 'trend', 'in', '[', 'information', 'retrieval', ']', 'systems', 'over', 'time', 'has', 'been', 'from', 'standard', 'use', 'of', 'quite', 'large', 'stop', 'lists', '(', '200–300', 'terms', ')', 'to', 'very', 'small', 'stop', 'lists', '(', '7–12', 'terms', ')', 'to', 'no', 'stop', 'list', 'whatsoever', \"''\", '.', '[', '2', ']']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stop words: Are Natural words which have a very littile meaning. For Example: a, the, etc.\n",
        "These words might take a lot of space in database. They can be removed by storing a list of stop words. In our import statements, we have imported stopwords from nltk corpus."
      ],
      "metadata": {
        "id": "N64lpE2uKQVU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words=set(stopwords.words('english'))\n",
        "print(stop_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nz3GLcEFJOyp",
        "outputId": "09ec5f74-f5dd-42d4-d011-3d979cc3bce0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'him', 'do', 'between', 'now', \"shan't\", 'wasn', \"won't\", \"don't\", \"haven't\", 'some', 'doing', \"mustn't\", \"hasn't\", 'themselves', 'above', 'at', 'being', 'ma', 'yourselves', 'for', 'weren', 'don', \"needn't\", 'both', 'should', 'who', \"hadn't\", 're', 'mustn', 'or', 'not', 'be', 'just', 'other', 'won', 'he', 'how', \"doesn't\", 'you', 'which', 'having', 'your', 'before', 'is', \"you'll\", 'herself', 'shan', 'few', 'these', 'what', 'her', 'she', 'under', 'yourself', 'then', 'did', 'whom', 've', 'hasn', 'them', 'm', 'more', 'we', 'while', 'yours', 'all', 'hers', \"isn't\", 'to', 'than', 'nor', 'by', 'during', 'as', 'are', 'with', 'mightn', 'after', 'i', 'this', \"that'll\", 'through', 'own', \"weren't\", 'wouldn', 'when', 'so', \"didn't\", 'but', 'over', 'those', 'a', 'they', 'of', 'same', \"you're\", 'if', \"couldn't\", 'couldn', 'hadn', 'once', 's', 'where', 'there', 'out', 'will', 'had', 'each', 'our', 'no', 'didn', 'isn', 'ours', 'its', \"aren't\", 'their', 'his', 'were', 'll', 'needn', \"shouldn't\", 't', 'again', 'very', 'down', 'only', 'about', 'ourselves', 'from', 'theirs', 'himself', 'an', 'most', 'that', 'ain', 'haven', 'itself', 'aren', 'shouldn', 'has', \"it's\", \"should've\", 'was', 'doesn', \"wasn't\", 'any', \"wouldn't\", 'off', 'up', 'myself', \"mightn't\", 'against', 'why', \"you'd\", 'does', 'until', 'd', 'me', 'further', 'y', 'in', 'my', 'o', 'on', 'such', 'too', 'below', \"she's\", 'have', 'and', 'into', \"you've\", 'because', 'here', 'the', 'am', 'it', 'can', 'been'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_sentence=[ w for w in tokenized_words if not w in stop_words ]"
      ],
      "metadata": {
        "id": "Q006p0FpLYUu"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Above way can be written as below"
      ],
      "metadata": {
        "id": "6C_uoomPMgz5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_sentence=[]\n",
        "for w in tokenized_words:\n",
        "  if w not in stop_words:\n",
        "    filtered_sentence.append(w)"
      ],
      "metadata": {
        "id": "yeVbF5-vMeJq"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(filtered_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LlPie_EM3Rt",
        "outputId": "34c8154e-106c-4f73-8062-4a5131f03c34"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Stop', 'words', 'words', 'stop', 'list', '(', 'stoplist', 'negative', 'dictionary', ')', 'filtered', '(', 'i.e', '.', 'stopped', ')', 'processing', 'natural', 'language', 'data', '(', 'text', ')', 'insignificant', '.', '[', '1', ']', 'There', 'single', 'universal', 'list', 'stop', 'words', 'used', 'natural', 'language', 'processing', 'tools', ',', 'agreed', 'upon', 'rules', 'identifying', 'stop', 'words', ',', 'indeed', 'tools', 'even', 'use', 'list', '.', 'Therefore', ',', 'group', 'words', 'chosen', 'stop', 'words', 'given', 'purpose', '.', 'The', '``', 'general', 'trend', '[', 'information', 'retrieval', ']', 'systems', 'time', 'standard', 'use', 'quite', 'large', 'stop', 'lists', '(', '200–300', 'terms', ')', 'small', 'stop', 'lists', '(', '7–12', 'terms', ')', 'stop', 'list', 'whatsoever', \"''\", '.', '[', '2', ']']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stemming: Is a process involved in reducing the word to stem or root form by removing suffixes.**"
      ],
      "metadata": {
        "id": "HNPd16SjNLIA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lemmaize: Grouping various inflected types of words so that they can be analized as one item**"
      ],
      "metadata": {
        "id": "l8AEdJmVN__y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem import PorterStemmer\n",
        "ps=PorterStemmer()\n",
        "ls=WordNetLemmatizer()\n",
        "text_sample='''India, officially the Republic of India (Hindi: Bhārat Gaṇarājya),[25] is a country in South Asia. It is the seventh-largest country by area, the second-most populous country, and the most populous democracy in the world. Bounded by the Indian Ocean on the south, the Arabian Sea on the southwest, and the Bay of Bengal on the southeast, it shares land borders with Pakistan to the west;[f] China, Nepal, and Bhutan to the north; and Bangladesh and Myanmar to the east. In the Indian Ocean, India is in the vicinity of Sri Lanka and the Maldives; its Andaman and Nicobar Islands share a maritime border with Thailand, Myanmar, and Indonesia. '''\n",
        "wordstoken=word_tokenize(text_sample)\n",
        "filtered_sentence=[ w for w in wordstoken if not w in stop_words ]\n",
        "for w in filtered_sentence:\n",
        "  print(\"Stemmed word :\"+ps.stem(w)+\" Lemmatized word :\"+ls.lemmatize(w))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlwuBPeNNZbD",
        "outputId": "9ec57707-6164-4d26-920a-6d3e5a46ea06"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stemmed word :india Lemmatized word :India\n",
            "Stemmed word :, Lemmatized word :,\n",
            "Stemmed word :offici Lemmatized word :officially\n",
            "Stemmed word :republ Lemmatized word :Republic\n",
            "Stemmed word :india Lemmatized word :India\n",
            "Stemmed word :( Lemmatized word :(\n",
            "Stemmed word :hindi Lemmatized word :Hindi\n",
            "Stemmed word :: Lemmatized word ::\n",
            "Stemmed word :bhārat Lemmatized word :Bhārat\n",
            "Stemmed word :gaṇarājya Lemmatized word :Gaṇarājya\n",
            "Stemmed word :) Lemmatized word :)\n",
            "Stemmed word :, Lemmatized word :,\n",
            "Stemmed word :[ Lemmatized word :[\n",
            "Stemmed word :25 Lemmatized word :25\n",
            "Stemmed word :] Lemmatized word :]\n",
            "Stemmed word :countri Lemmatized word :country\n",
            "Stemmed word :south Lemmatized word :South\n",
            "Stemmed word :asia Lemmatized word :Asia\n",
            "Stemmed word :. Lemmatized word :.\n",
            "Stemmed word :it Lemmatized word :It\n",
            "Stemmed word :seventh-largest Lemmatized word :seventh-largest\n",
            "Stemmed word :countri Lemmatized word :country\n",
            "Stemmed word :area Lemmatized word :area\n",
            "Stemmed word :, Lemmatized word :,\n",
            "Stemmed word :second-most Lemmatized word :second-most\n",
            "Stemmed word :popul Lemmatized word :populous\n",
            "Stemmed word :countri Lemmatized word :country\n",
            "Stemmed word :, Lemmatized word :,\n",
            "Stemmed word :popul Lemmatized word :populous\n",
            "Stemmed word :democraci Lemmatized word :democracy\n",
            "Stemmed word :world Lemmatized word :world\n",
            "Stemmed word :. Lemmatized word :.\n",
            "Stemmed word :bound Lemmatized word :Bounded\n",
            "Stemmed word :indian Lemmatized word :Indian\n",
            "Stemmed word :ocean Lemmatized word :Ocean\n",
            "Stemmed word :south Lemmatized word :south\n",
            "Stemmed word :, Lemmatized word :,\n",
            "Stemmed word :arabian Lemmatized word :Arabian\n",
            "Stemmed word :sea Lemmatized word :Sea\n",
            "Stemmed word :southwest Lemmatized word :southwest\n",
            "Stemmed word :, Lemmatized word :,\n",
            "Stemmed word :bay Lemmatized word :Bay\n",
            "Stemmed word :bengal Lemmatized word :Bengal\n",
            "Stemmed word :southeast Lemmatized word :southeast\n",
            "Stemmed word :, Lemmatized word :,\n",
            "Stemmed word :share Lemmatized word :share\n",
            "Stemmed word :land Lemmatized word :land\n",
            "Stemmed word :border Lemmatized word :border\n",
            "Stemmed word :pakistan Lemmatized word :Pakistan\n",
            "Stemmed word :west Lemmatized word :west\n",
            "Stemmed word :; Lemmatized word :;\n",
            "Stemmed word :[ Lemmatized word :[\n",
            "Stemmed word :f Lemmatized word :f\n",
            "Stemmed word :] Lemmatized word :]\n",
            "Stemmed word :china Lemmatized word :China\n",
            "Stemmed word :, Lemmatized word :,\n",
            "Stemmed word :nepal Lemmatized word :Nepal\n",
            "Stemmed word :, Lemmatized word :,\n",
            "Stemmed word :bhutan Lemmatized word :Bhutan\n",
            "Stemmed word :north Lemmatized word :north\n",
            "Stemmed word :; Lemmatized word :;\n",
            "Stemmed word :bangladesh Lemmatized word :Bangladesh\n",
            "Stemmed word :myanmar Lemmatized word :Myanmar\n",
            "Stemmed word :east Lemmatized word :east\n",
            "Stemmed word :. Lemmatized word :.\n",
            "Stemmed word :in Lemmatized word :In\n",
            "Stemmed word :indian Lemmatized word :Indian\n",
            "Stemmed word :ocean Lemmatized word :Ocean\n",
            "Stemmed word :, Lemmatized word :,\n",
            "Stemmed word :india Lemmatized word :India\n",
            "Stemmed word :vicin Lemmatized word :vicinity\n",
            "Stemmed word :sri Lemmatized word :Sri\n",
            "Stemmed word :lanka Lemmatized word :Lanka\n",
            "Stemmed word :maldiv Lemmatized word :Maldives\n",
            "Stemmed word :; Lemmatized word :;\n",
            "Stemmed word :andaman Lemmatized word :Andaman\n",
            "Stemmed word :nicobar Lemmatized word :Nicobar\n",
            "Stemmed word :island Lemmatized word :Islands\n",
            "Stemmed word :share Lemmatized word :share\n",
            "Stemmed word :maritim Lemmatized word :maritime\n",
            "Stemmed word :border Lemmatized word :border\n",
            "Stemmed word :thailand Lemmatized word :Thailand\n",
            "Stemmed word :, Lemmatized word :,\n",
            "Stemmed word :myanmar Lemmatized word :Myanmar\n",
            "Stemmed word :, Lemmatized word :,\n",
            "Stemmed word :indonesia Lemmatized word :Indonesia\n",
            "Stemmed word :. Lemmatized word :.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem import PorterStemmer\n",
        "ps=PorterStemmer()\n",
        "ls=WordNetLemmatizer()\n",
        "text_sample='''India, officially the Republic of India (Hindi: Bhārat Gaṇarājya),[25] is a country in South Asia. It is the seventh-largest country by area, the second-most populous country, and the most populous democracy in the world. Bounded by the Indian Ocean on the south, the Arabian Sea on the southwest, and the Bay of Bengal on the southeast, it shares land borders with Pakistan to the west;[f] China, Nepal, and Bhutan to the north; and Bangladesh and Myanmar to the east. In the Indian Ocean, India is in the vicinity of Sri Lanka and the Maldives; its Andaman and Nicobar Islands share a maritime border with Thailand, Myanmar, and Indonesia. '''\n",
        "senttokenize=sent_tokenize(text_sample)\n",
        "for i in senttokenize:\n",
        "  wordsList=nltk.word_tokenize(i)\n",
        "  wordsList=[ w for w in wordsList if not w in stop_words ] \n",
        "  tagged=nltk.pos_tag(wordsList)\n",
        "  print(tagged)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4GI0QLWRp1c",
        "outputId": "1946cfe3-f3b8-456d-9607-011daf58a4aa"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('India', 'NNP'), (',', ','), ('officially', 'RB'), ('Republic', 'NNP'), ('India', 'NNP'), ('(', '('), ('Hindi', 'NNP'), (':', ':'), ('Bhārat', 'NNP'), ('Gaṇarājya', 'NNP'), (')', ')'), (',', ','), ('[', '$'), ('25', 'CD'), (']', 'JJ'), ('country', 'NN'), ('South', 'NNP'), ('Asia', 'NNP'), ('.', '.')]\n",
            "[('It', 'PRP'), ('seventh-largest', 'JJ'), ('country', 'NN'), ('area', 'NN'), (',', ','), ('second-most', 'JJ'), ('populous', 'JJ'), ('country', 'NN'), (',', ','), ('populous', 'JJ'), ('democracy', 'NN'), ('world', 'NN'), ('.', '.')]\n",
            "[('Bounded', 'NNP'), ('Indian', 'JJ'), ('Ocean', 'NNP'), ('south', 'NN'), (',', ','), ('Arabian', 'NNP'), ('Sea', 'NNP'), ('southwest', 'JJS'), (',', ','), ('Bay', 'NNP'), ('Bengal', 'NNP'), ('southeast', 'NN'), (',', ','), ('shares', 'NNS'), ('land', 'VBP'), ('borders', 'NNS'), ('Pakistan', 'NNP'), ('west', 'NN'), (';', ':'), ('[', 'CC'), ('f', 'JJ'), (']', 'NNP'), ('China', 'NNP'), (',', ','), ('Nepal', 'NNP'), (',', ','), ('Bhutan', 'NNP'), ('north', 'NN'), (';', ':'), ('Bangladesh', 'NNP'), ('Myanmar', 'NNP'), ('east', 'NN'), ('.', '.')]\n",
            "[('In', 'IN'), ('Indian', 'JJ'), ('Ocean', 'NNP'), (',', ','), ('India', 'NNP'), ('vicinity', 'NN'), ('Sri', 'NNP'), ('Lanka', 'NNP'), ('Maldives', 'NNP'), (';', ':'), ('Andaman', 'NNP'), ('Nicobar', 'NNP'), ('Islands', 'NNP'), ('share', 'NN'), ('maritime', 'JJ'), ('border', 'NN'), ('Thailand', 'NNP'), (',', ','), ('Myanmar', 'NNP'), (',', ','), ('Indonesia', 'NNP'), ('.', '.')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Named Entity Recognition**"
      ],
      "metadata": {
        "id": "gynfB6epSoX3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "text_sample='''India, officially the Republic of India (Hindi: Bhārat Gaṇarājya),[25] is a country in South Asia. It is the seventh-largest country by area, the second-most populous country, and the most populous democracy in the world. Bounded by the Indian Ocean on the south, the Arabian Sea on the southwest, and the Bay of Bengal on the southeast, it shares land borders with Pakistan to the west;[f] China, Nepal, and Bhutan to the north; and Bangladesh and Myanmar to the east. In the Indian Ocean, India is in the vicinity of Sri Lanka and the Maldives; its Andaman and Nicobar Islands share a maritime border with Thailand, Myanmar, and Indonesia. '''\n",
        "#tokenized doc\n",
        "tokenized_doc=nltk.word_tokenize(text_sample)\n",
        "tagged_sentence=nltk.pos_tag(tokenized_doc)\n",
        "ne_chunked_sentence=nltk.ne_chunk(tagged_sentence)\n",
        "# Extracting all named entity\n",
        "named_entities=[]\n",
        "for tagged_tree in ne_chunked_sentence:\n",
        "  if hasattr(tagged_tree,'label'):\n",
        "    entity_name=' '.join(c[0] for c in tagged_tree.leaves())\n",
        "    entity_type=tagged_tree.label();\n",
        "    named_entities.append((entity_name,entity_type))\n",
        "print(named_entities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bBpeFptOfcj",
        "outputId": "1e2ed0b6-1751-4cef-d294-806575fa2ba7"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('India', 'GPE'), ('Republic', 'ORGANIZATION'), ('India', 'GPE'), ('Bhārat Gaṇarājya', 'PERSON'), ('South Asia', 'GPE'), ('Indian', 'GPE'), ('Ocean', 'LOCATION'), ('Arabian Sea', 'PERSON'), ('Bay', 'ORGANIZATION'), ('Bengal', 'GPE'), ('Pakistan', 'GPE'), ('China', 'GPE'), ('Nepal', 'PERSON'), ('Bhutan', 'GPE'), ('Bangladesh', 'ORGANIZATION'), ('Myanmar', 'PERSON'), ('Indian Ocean', 'GPE'), ('India', 'GPE'), ('Sri Lanka', 'ORGANIZATION'), ('Maldives', 'ORGANIZATION'), ('Andaman', 'PERSON'), ('Nicobar Islands', 'PERSON'), ('Thailand', 'GPE'), ('Myanmar', 'PERSON'), ('Indonesia', 'GPE')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        }
      ]
    }
  ]
}